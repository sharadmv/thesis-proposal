@book{cem,
    author={R. Rubinstein and D. Kroese},
    title={The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, {M}onte-{C}arlo Simulation (Information Science and Statistics)},
    publisher={Springer-Verlag New York, Inc.},
    year={2004},
}

@book{convex,
    author={S. Boyd and L. Vandenberghe},
    title={Convex Optimization},
    publisher={Cambridge University Press},
    year={2004},
}

@book{ddp,
    author={D. Jacobson and D. Mayne},
    title={Differential Dynamic Programming},
    publisher={American Elsevier},
    year={1970},
}

@book{ilc,
    author={C. An and C. Atkeson and J. Hollerbach},
    title={Model-Based Control of a Robot Manipulator},
    publisher={MIT Press},
    year={1988},
}

@book{mpc,
    author={E. Camacho and C. Bordons},
    title={Model Predictive Control in the Process Industry},
    publisher={Springer-Verlag New York, Inc.},
    year={1997},
}

@book{oc,
    author={R. Vinter},
    title={Optimal Control},
    publisher={Birkhäuser},
    year={2010},
}

@article{dimension-reduction,
    author={A. Nouri and M. Littman},
    title={Dimension Reduction and Its Application to Model-Based Exploration in Continuous Spaces},
    journal={Machine Learning},
    year={2010},
}

@article{es,
    author={T. Salimans and J. Ho and X. Chen and I. Sutskever},
    title={Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
    journal={arXiv preprint arXiv:1703.03864},
    year={2017},
}

@article{gps,
    author={S. Levine and C. Finn and T. Darrell and P. Abbeel},
    title={End-to-end Training of Deep Visuomotor Policies},
    journal={JMLR},
    year={2016},
}

@article{gym,
    author={G. Brockman and V. Cheung and L. Pettersson and J. Schneider and J. Schulman and J. Tang and W. Zaremba},
    title={{OpenAI} Gym},
    journal={arXiv preprint arXiv:1606.01540},
    year={2016},
}

@article{pi2,
    author={E. Theodorou and J. Buchli and S. Schaal},
    title={A Generalized Path Integral Control Approach to Reinforcement Learning},
    journal={JMLR},
    year={2010},
}

@article{pilco,
    author={M. Deisenroth and D. Fox and C. Rasmussen},
    title={Gaussian Processes for Data-Efficient Learning in Robotics and Control},
    journal={PAMI},
    year={2014},
}

@article{pilqr,
    author={Y. Chebotar and K. Hausman and M. Zhang and G. Sukhatme and S. Schaal and S. Levine},
    title={Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning},
    journal={arXiv preprint arXiv:1703.03078},
    year={2017},
}

@article{reinforce,
    author={R. Williams},
    title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
    journal={Machine Learning},
    year={1992},
}

@article{rl-robotics-survey,
    author={J. Kober and J. Bagnell and J. Peters},
    title={Reinforcement Learning in Robotics: A Survey},
    journal={IJRR},
    year={2013},
}

@article{rl2,
    author={Y. Duan and J. Schulman and X. Chen and P. Bartlett and I. Sutskever and P. Abbeel},
    title={{RL}$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning},
    journal={arXiv preprint arXiv:1611.02779},
    year={2016},
}

@article{self-organizing-map,
    author={A. Smith},
    title={Applications of the Self-Organizing Map to Reinforcement Learning},
    journal={Neural Networks},
    year={2002},
}

@article{temporal-segment-models,
    author={N. Mishra and I. Mordatch and P. Abbeel},
    title={Prediction and Control with Temporal Segment Models},
    journal={arXiv preprint arXiv:1703.04070},
    year={2017},
}

@article{transfer-learning-survey,
	author={M. Taylor and P. Stone},
	title={Transfer Learning for Reinforcement Learning Domains: A Survey},
	journal={JMLR},
	year={2009},
}

@article{vmp,
    author={J. Winn and C. Bishop},
    title={Variational Message Passing},
    journal={JMLR},
    year={2005},
}


@inproceedings{ae-nn,
    author={S. Lange and M. Riedmiller},
    title={Deep Auto-Encoder Neural Networks in Reinforcement Learning},
    booktitle={IJCNN},
    year={2010},
}

@inproceedings{bm,
    author={S. Khansari-Zadeh and A. Billard},
    title={{BM}: An Iterative Algorithm to Learn Stable Non-Linear Dynamical Systems with {G}aussian Mixture Models},
    booktitle={ICRA},
    year={2010},
}

@inproceedings{covariant-policy-search,
    author={J. Bagnell and J. Schneider},
    title={Covariant Policy Search},
    booktitle={IJCAI},
    year={2003},
}

@inproceedings{ddpg,
    author={T. Lillicrap and J. Hunt and A. Pritzel and N. Heess and T. Erez and Y. Tassa and D. Silver and D. Wierstra},
    title={Continuous Control with Deep Reinforcement Learning},
    booktitle={ICLR},
    year={2016},
}

@inproceedings{dqn,
    author={V. Mnih and K. Kavukcuoglu and D. Silver and A. Graves and I. Antonoglou and D. Wierstra and M. Riedmiller},
    title={Playing {A}tari with Deep Reinforcement Learning},
    booktitle={NIPS Workshop on Deep Learning},
    year={2013},
}

@inproceedings{dyna,
    author={R. Sutton},
    title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle={ICML},
    year={1990},
}

@inproceedings{e2c,
    author={M. Watter and J. Springenberg and J. Boedecker and M. Riedmiller},
    title={Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
    booktitle={NIPS},
    year={2015},
}

@inproceedings{gae,
    author={J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
    title={High-Dimensional Continuous Control Using Generalized Advantage Estimation},
    booktitle={ICLR},
    year={2016},
}

@inproceedings{gan,
    author={I. Goodfellow and J. Pouget-Abadie and M. Mirza and B. Xu and D. Warde-Farley and S. Ozair and A. Courville and Y. Bengio},
    title={Generative Adversarial Networks},
    booktitle={NIPS},
    year={2014},
}

@inproceedings{gps-orig,
    author={S. Levine and V. Koltun},
    title={Guided Policy Search},
    booktitle={ICML},
    year={2013},
}

@inproceedings{iaf,
    author={D. Kingma and T. Salimans and R. Jozefowicz and X. Chen and I. Sutskever and M. Welling},
    title={Improving Variational Inference with Inverse Autoregressive Flow},
    booktitle={NIPS},
    year={2016},
}

@inproceedings{ilqg,
    author={E. Todorov and W. Li},
    title={A Generalized Iterative {LQG} Method for Locally-optimal Feedback Control of Constrained Nonlinear Stochastic Systems},
    booktitle={ACC},
    year={2005},
}

@inproceedings{infogan,
    author={X. Chen and Y. Duan and R. Houthooft and J. Schulman and I. Sutskever and P. Abbeel},
    title={Info{GAN}: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
    booktitle={NIPS},
    year={2016},
}

@inproceedings{invariant-feature-spaces,
    author={A. Gupta and C. Devin and Y. Liu and P. Abbeel and S. Levine},
    title={Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning},
    booktitle={ICLR},
    year={2017},
}

@inproceedings{mfcgps,
    author={S. Levine and P. Abbeel},
    title={Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
    booktitle={NIPS},
    year={2014},
}

@inproceedings{mujoco,
    author={E. Todorov and T. Erez and Y. Tassa},
    title={Mu{J}o{C}o: A Physics Engine for Model-Based Control},
    booktitle={IROS},
    year={2012},
}

@inproceedings{naf,
    author={S. Gu and T. Lillicrap and I. Sutskever and S. Levine},
    title={Continuous Deep {Q}-Learning with Model-based Acceleration},
    booktitle={ICML},
    year={2016},
}


@inproceedings{pddp,
    author={Y. Pan and E. Theodorou.},
    title={Probabilistic Differential Dynamic Programming},
    booktitle={NIPS},
    year={2014},
}

@inproceedings{pigps,
	author={Y. Chebotar and M. Kalakrishnan and A. Yahya and A. Li and S. Schaal and S. Levine},
	title={Path Integral Guided Policy Search},
	booktitle={ICRA},
	year={2017},
}

@inproceedings{qprop,
    author={S. Gu and T. Lillicrap and Z. Ghahramani and R. Turner and S. Levine},
    title={Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic},
    booktitle={ICLR},
    year={2017},
}

@inproceedings{real-nvp,
    author={L. Dinh and J. Sohl-Dickstein and S. Bengio},
    title={Density Estimation Using Real {NVP}},
    booktitle={ICLR},
    year={2017},
}

@inproceedings{recurrent-network-models,
    author={K. Fragkiadaki and S. Levine and P. Felsen and J. Malik},
    title={Recurrent Network Models for Human Dynamics},
    booktitle={ICCV},
    year={2015},
}

@inproceedings{reps,
    author={J. Peters and K. Mülling and Y. Altün},
    title={Relative Entropy Policy Search},
    booktitle={AAAI},
    year={2010},
}

@inproceedings{robot-lfd,
    author={C. Atkeson and S. Schaal},
    title={Robot Learning from Demonstration},
    booktitle={ICML},
    year={1997},
}

@inproceedings{robotgps,
    author={S. Levine and N. Wagener and P. Abbeel},
    title={Learning Contact-Rich Manipulation Skills with Guided Policy Search},
    booktitle={ICRA},
    year={2015},
}

@inproceedings{sign-derivative,
    author={J. Kolter and A. Ng},
    title={Policy Search via the Signed Derivative},
    booktitle={RSS},
    year={2005},
}

@inproceedings{soft-state-aggregation,
    author={S. Singh and T. Jaakkola and M. Jordan},
    title={Reinforcement Learning with Soft State Aggregation},
    booktitle={NIPS},
    year={1994},
}

@inproceedings{spatial-ae,
    author={C. Finn and X. Tan and Y. Duan and T. Darrell and S. Levine and P. Abbeel},
    title={Deep Spatial Autoencoders for Visuomotor Learning},
    booktitle={ICRA},
    year={2016},
}

@inproceedings{superhuman-surgical,
    author={J. van den Berg and S. Miller and D. Duckworth and H. Hu and A. Wan and X. Fu and K. Goldberg and P. Abbeel},
    title={Superhuman Performance of Surgical Tasks by Robots Using Iterative Learning from Human-Guided Demonstrations},
    booktitle={ICRA},
    year={2010},
}

@inproceedings{svae,
    author={M. Johnson and D. Duvenaud and A. Wiltschko and S. Datta and R. Adams},
    title={Composing Graphical Models with Neural Networks for Structured Representations and Fast Inference},
    booktitle={NIPS},
    year={2016},
}

@inproceedings{svg,
    author={N. Heess and G. Wayne and D. Silver and T. Lillicrap and Y. Tassa and T. Erez},
    title={Learning Continuous Control Policies by Stochastic Value Gradients},
    booktitle={NIPS},
    year={2015},
}

@inproceedings{synthesis,
    author={Y. Tassa and T. Erez and E. Todorov},
    title={Synthesis and Stabilization of Complex Behaviors},
    booktitle={IROS},
    year={2012},
}

@inproceedings{trpo,
    author={J. Schulman and S. Levine and P. Moritz and M. Jordan and P. Abbeel},
    title={Trust Region Policy Optimization},
    booktitle={ICML},
    year={2015},
} 

@inproceedings{vae-kingma,
    author={D. Kingma and M. Welling},
    title={Auto-Encoding Variational {B}ayes},
    booktitle={ICLR},
    year={2014},
}

@inproceedings{vae-rezende,
    author={D. Rezende and S. Mohamed and D. Wierstra},
    title={Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
    booktitle={ICML},
    year={2014},
}

@inproceedings{vin,
    author={A. Tamar and Y. Wu and G. Thomas and S. Levine and P. Abbeel},
    title={Value Iteration Networks},
    booktitle={NIPS},
    year={2016},
}

@inproceedings{vlae,
    author={X. Chen and D. Kingma and T. Salimans and Y. Duan and P. Dhariwal and J. Schulman and I. Sutskever and P. Abbeel},
    title={Variational Lossy Autoencoder},
    booktitle={ICLR},
    year={2017},
}
@article{blackbox,
abstract = {Variational inference has become a widely used method to approximate posteriors in complex latent variables models. However, deriving a variational inference algorithm generally requires significant model-specific analysis, and these efforts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand. In this paper, we present a "black box" variational inference algorithm, one that can be quickly applied to many models with little additional derivation. Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution. We develop a number of methods to reduce the variance of the gradient, always maintaining the criterion that we want to avoid difficult model-based derivations. We evaluate our method against the corresponding black box sampling based methods. We find that our method reaches better predictive likelihoods much faster than sampling methods. Finally, we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data.},
archivePrefix = {arXiv},
arxivId = {1401.0118},
author = {Ranganath, Rajesh and Gerrish, Sean and Blei, David M.},
eprint = {1401.0118},
file = {:home/sharad/Documents/Mendeley Desktop/Ranganath, Gerrish, Blei - 2013 - Black Box Variational Inference.pdf:pdf},
month = {dec},
title = {{Black Box Variational Inference}},
url = {http://arxiv.org/abs/1401.0118},
year = {2013}
}
@article{vae,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
doi = {10.1051/0004-6361/201527329},
eprint = {1312.6114},
file = {:home/sharad/Documents/Mendeley Desktop/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes.pdf:pdf},
isbn = {1312.6114v10},
issn = {1312.6114v10},
mendeley-groups = {ICML 2016},
month = {dec},
pmid = {23459267},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}

